{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Kmu-yO52tK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BZpMgVMzHVg"
      },
      "outputs": [],
      "source": [
        "# Importar el csv de entrenamiento a una variable de pandas.\n",
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEzpkEZ1lLrD"
      },
      "outputs": [],
      "source": [
        "Y_train = df_train['label'].values\n",
        "X_train = df_train.drop('label', axis=1).values\n",
        "\n",
        "# X es el conjunto de datos, e Y es la etiqueta\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpPNlNgSl86g"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "Y_train = torch.from_numpy(Y_train).long()\n",
        "Y_test = torch.from_numpy(Y_test).long()\n",
        "\n",
        "X_train = X_train.view(-1, 1, 28, 28) #linea anterior: X_train = X_train.view(-1, 28, 28)\n",
        "X_test = X_test.view(-1, 1, 28, 28) #linea anterior: X_test = X_test.view((-1, 28, 28)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM0LcLdTiPet"
      },
      "outputs": [],
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset( \n",
        "            X_train,\n",
        "            Y_train\n",
        "        ),\n",
        "        batch_size=64,\n",
        "        shuffle=True\n",
        "    ),\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(\n",
        "          X_test,\n",
        "          Y_test\n",
        "        ),\n",
        "        batch_size=64,\n",
        "        shuffle=True\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF_foPg47jYi"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7UqBJugBmpf"
      },
      "outputs": [],
      "source": [
        "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(pk, stride=ps)\n",
        "    )\n",
        "\n",
        "def block2(c_in, c_out):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Linear(c_in, c_out),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, n_channels=1, n_outputs=10):\n",
        "    super().__init__()\n",
        "    self.conv1 = block(n_channels, 64)\n",
        "    self.conv2 = block(64, 128)\n",
        "    self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plq1fIAFc6qv"
      },
      "outputs": [],
      "source": [
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print()\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2if6Fk6fQnra"
      },
      "outputs": [],
      "source": [
        "model = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hky4eyXWXjDi",
        "outputId": "4efedc19-f75a-495c-bf7d-799fdf9a868b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.63836 acc 0.93182: 100%|██████████| 525/525 [01:37<00:00,  5.37it/s]\n",
            "val_loss 0.16090 val_acc 0.95407: 100%|██████████| 132/132 [00:09<00:00, 13.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5 loss 0.63836 val_loss 0.16090 acc 0.93182 val_acc 0.95407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.11116 acc 0.96854: 100%|██████████| 525/525 [01:40<00:00,  5.22it/s]\n",
            "val_loss 0.14344 val_acc 0.96697: 100%|██████████| 132/132 [00:10<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/5 loss 0.11116 val_loss 0.14344 acc 0.96854 val_acc 0.96697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.10301 acc 0.97119: 100%|██████████| 525/525 [01:39<00:00,  5.29it/s]\n",
            "val_loss 0.10551 val_acc 0.97242: 100%|██████████| 132/132 [00:09<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/5 loss 0.10301 val_loss 0.10551 acc 0.97119 val_acc 0.97242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.08937 acc 0.97473: 100%|██████████| 525/525 [01:38<00:00,  5.32it/s]\n",
            "val_loss 0.11099 val_acc 0.97408: 100%|██████████| 132/132 [00:09<00:00, 14.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/5 loss 0.08937 val_loss 0.11099 acc 0.97473 val_acc 0.97408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.06569 acc 0.98173: 100%|██████████| 525/525 [01:38<00:00,  5.30it/s]\n",
            "val_loss 0.10848 val_acc 0.97384: 100%|██████████| 132/132 [00:09<00:00, 13.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/5 loss 0.06569 val_loss 0.10848 acc 0.98173 val_acc 0.97384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fit(model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = torch.from_numpy(df_test.to_numpy()).float()\n",
        "\n",
        "df_test = df_test.view(-1, 1, 28, 28) "
      ],
      "metadata": {
        "id": "3EWfKV_cjnRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_predict = {\n",
        "    'predict': torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(df_test),\n",
        "        batch_size=64\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "oSOUvmojlnYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar = tqdm(dataloader_predict['predict'])\n",
        "predict = []\n",
        "for batch in bar:\n",
        "    for tensor in batch:\n",
        "      X = tensor\n",
        "      X = X.to(device)\n",
        "      y_hat = model(X)\n",
        "      predict.append(torch.argmax(y_hat, axis=1))\n",
        "      bar.set_description()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBpVL7PimwIY",
        "outputId": "cd99ad33-2675-4dbc-adad-bf333acc9305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 438/438 [00:32<00:00, 13.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = torch.cat(predict, dim=0)"
      ],
      "metadata": {
        "id": "mPxKTXb8xbyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImageId = list(range(1,28001))"
      ],
      "metadata": {
        "id": "wEaXiBnwk73W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample =  pd.DataFrame({\"ImageId\":ImageId, \"Label\":predicts})"
      ],
      "metadata": {
        "id": "pS0X8CQdlT2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.to_csv(\"Predicciones_MNIST.csv\", index=False)"
      ],
      "metadata": {
        "id": "KHsd53Iq2syQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3SS6+/KoqP6iWoOnmFgux"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}