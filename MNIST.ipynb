{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MJ7D88ruCV-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "00Kmu-yO52tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el csv de entrenamiento a una variable de pandas.\n",
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "2BZpMgVMzHVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = df_train['label'].values\n",
        "X_train = df_train.drop('label', axis=1).values\n",
        "\n",
        "# X es el conjunto de datos, e Y es la etiqueta\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "FEzpkEZ1lLrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqx50w5plcEQ",
        "outputId": "98983bf5-c36e-4fba-c8c9-2110b8b2a110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "Y_train = torch.from_numpy(Y_train).long()\n",
        "Y_test = torch.from_numpy(Y_test).long()\n",
        "\n",
        "X_train = X_train.view(-1, 1, 28, 28) #linea anterior: X_train = X_train.view(-1, 28, 28)\n",
        "X_test = X_test.view(-1, 1, 28, 28) #linea anterior: X_test = X_test.view((-1, 28, 28)\n"
      ],
      "metadata": {
        "id": "hpPNlNgSl86g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando dataset\n",
        "img = np.array(X_train[100][0])\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PQ9bGBPkl_VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[100]"
      ],
      "metadata": {
        "id": "2UHYOfpA00Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(\n",
        "            torch.tensor(X_train, dtype=torch.float32),\n",
        "            torch.tensor(Y_train, dtype=torch.long)\n",
        "        ),\n",
        "        batch_size=64,\n",
        "        shuffle=True\n",
        "    ),\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(\n",
        "            torch.tensor(X_test, dtype=torch.float32),\n",
        "            torch.tensor(X_test, dtype=torch.long)\n",
        "        ),\n",
        "        batch_size=64,\n",
        "        shuffle=True\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "QM0LcLdTiPet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3cf289-0aa0-4291-81e0-f545e84b72d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b365525561e8>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(X_train, dtype=torch.float32),\n",
            "<ipython-input-7-b365525561e8>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(Y_train, dtype=torch.long)\n",
            "<ipython-input-7-b365525561e8>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(X_test, dtype=torch.float32),\n",
            "<ipython-input-7-b365525561e8>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(X_test, dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar en una variable un batch del dataloader de entrenamiento.\n",
        "batch = next(iter(dataloader['train']))\n",
        "batch[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKPSMWY6h2f-",
        "outputId": "2825fbed-061a-43a7-fcd4-f3af4699be70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldsT0FQaEjGa",
        "outputId": "59da82f6-eaaa-40b9-f283-2bef4fa834b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8400"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "qF_foPg47jYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(pk, stride=ps)\n",
        "    )\n",
        "\n",
        "def block2(c_in, c_out):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Linear(c_in, c_out),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, n_channels=1, n_outputs=10):\n",
        "    super().__init__()\n",
        "    self.conv1 = block(n_channels, 64)\n",
        "    self.conv2 = block(64, 128)\n",
        "    self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "k7UqBJugBmpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "V71KF7IOBiRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def init(self):\n",
        "        super(ConvNet, self).init()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5_6dz-OJoAuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "yZysMI3R-Xld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple = nn.Sequential(\n",
        "    nn.Conv2d(64, 1, 28)\n",
        ")"
      ],
      "metadata": {
        "id": "7K30Vvi3-dQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = simple"
      ],
      "metadata": {
        "id": "8uk4kbJF8uAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "AbaYzjSGENI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "g_zarsLV4saT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for x_batch, y_batch in dataloader['train']:\n",
        "    y_pred = model(x_batch)\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "dlYGbO2a4yOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "bJoEcHzAEY1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ],
      "metadata": {
        "id": "rpO00f-_7yUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")"
      ],
      "metadata": {
        "id": "plq1fIAFc6qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, dataloader, epochs=10, log_each=1):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "    l = []\n",
        "    model.train()\n",
        "    for e in range(1, epochs+1): \n",
        "        _l = []\n",
        "        for x_b, y_b in dataloader:\n",
        "            y_pred = model(x_b)\n",
        "            loss = criterion(y_pred, y_b)\n",
        "            _l.append(loss.item())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        l.append(np.mean(_l))\n",
        "        if not e % log_each:\n",
        "            print(f\"Epoch {e}/{epochs} loss {l[-1]:.5f}\")\n",
        "    return {'epoch': list(range(1, epochs+1)), 'loss': l}"
      ],
      "metadata": {
        "id": "UvZRiOKnaH15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()"
      ],
      "metadata": {
        "id": "2if6Fk6fQnra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hky4eyXWXjDi",
        "outputId": "7fe544b1-6856-4c5a-e453-9e0e8787eb6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss nan acc 0.10213: 100%|██████████| 58/58 [00:10<00:00,  5.64it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 loss nan acc 0.10213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\n",
            "\n",
            "loss nan acc 0.10938:   0%|          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "loss nan acc 0.10938:   2%|▏         | 1/58 [00:00<00:11,  5.13it/s]\u001b[A\n",
            "loss nan acc 0.11719:   2%|▏         | 1/58 [00:00<00:11,  5.13it/s]\u001b[A\n",
            "loss nan acc 0.11719:   3%|▎         | 2/58 [00:00<00:10,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.10938:   3%|▎         | 2/58 [00:00<00:10,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.10938:   5%|▌         | 3/58 [00:00<00:10,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.09375:   5%|▌         | 3/58 [00:00<00:10,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.09375:   7%|▋         | 4/58 [00:00<00:09,  5.48it/s]\u001b[A\n",
            "loss nan acc 0.08750:   7%|▋         | 4/58 [00:00<00:09,  5.48it/s]\u001b[A\n",
            "loss nan acc 0.08750:   9%|▊         | 5/58 [00:00<00:09,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.08333:   9%|▊         | 5/58 [00:01<00:09,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.08333:  10%|█         | 6/58 [00:01<00:10,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.09152:  10%|█         | 6/58 [00:01<00:10,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.09152:  12%|█▏        | 7/58 [00:01<00:11,  4.53it/s]\u001b[A\n",
            "loss nan acc 0.09375:  12%|█▏        | 7/58 [00:01<00:11,  4.53it/s]\u001b[A\n",
            "loss nan acc 0.09375:  14%|█▍        | 8/58 [00:01<00:12,  4.11it/s]\u001b[A\n",
            "loss nan acc 0.09549:  14%|█▍        | 8/58 [00:01<00:12,  4.11it/s]\u001b[A\n",
            "loss nan acc 0.09549:  16%|█▌        | 9/58 [00:02<00:12,  3.86it/s]\u001b[A\n",
            "loss nan acc 0.10000:  16%|█▌        | 9/58 [00:02<00:12,  3.86it/s]\u001b[A\n",
            "loss nan acc 0.10000:  17%|█▋        | 10/58 [00:02<00:13,  3.66it/s]\u001b[A\n",
            "loss nan acc 0.09659:  17%|█▋        | 10/58 [00:02<00:13,  3.66it/s]\u001b[A\n",
            "loss nan acc 0.09659:  19%|█▉        | 11/58 [00:02<00:13,  3.61it/s]\u001b[A\n",
            "loss nan acc 0.10026:  19%|█▉        | 11/58 [00:02<00:13,  3.61it/s]\u001b[A\n",
            "loss nan acc 0.10026:  21%|██        | 12/58 [00:02<00:13,  3.49it/s]\u001b[A\n",
            "loss nan acc 0.10216:  21%|██        | 12/58 [00:03<00:13,  3.49it/s]\u001b[A\n",
            "loss nan acc 0.10216:  22%|██▏       | 13/58 [00:03<00:12,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.10045:  22%|██▏       | 13/58 [00:03<00:12,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.10045:  24%|██▍       | 14/58 [00:03<00:12,  3.43it/s]\u001b[A\n",
            "loss nan acc 0.10000:  24%|██▍       | 14/58 [00:03<00:12,  3.43it/s]\u001b[A\n",
            "loss nan acc 0.10000:  26%|██▌       | 15/58 [00:03<00:12,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.09863:  26%|██▌       | 15/58 [00:04<00:12,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.09863:  28%|██▊       | 16/58 [00:04<00:12,  3.39it/s]\u001b[A\n",
            "loss nan acc 0.09651:  28%|██▊       | 16/58 [00:04<00:12,  3.39it/s]\u001b[A\n",
            "loss nan acc 0.09651:  29%|██▉       | 17/58 [00:04<00:12,  3.40it/s]\u001b[A\n",
            "loss nan acc 0.09462:  29%|██▉       | 17/58 [00:04<00:12,  3.40it/s]\u001b[A\n",
            "loss nan acc 0.09462:  31%|███       | 18/58 [00:04<00:10,  3.77it/s]\u001b[A\n",
            "loss nan acc 0.09375:  31%|███       | 18/58 [00:04<00:10,  3.77it/s]\u001b[A\n",
            "loss nan acc 0.09375:  33%|███▎      | 19/58 [00:04<00:09,  4.08it/s]\u001b[A\n",
            "loss nan acc 0.09453:  33%|███▎      | 19/58 [00:04<00:09,  4.08it/s]\u001b[A\n",
            "loss nan acc 0.09453:  34%|███▍      | 20/58 [00:04<00:08,  4.41it/s]\u001b[A\n",
            "loss nan acc 0.09301:  34%|███▍      | 20/58 [00:05<00:08,  4.41it/s]\u001b[A\n",
            "loss nan acc 0.09301:  36%|███▌      | 21/58 [00:05<00:07,  4.71it/s]\u001b[A\n",
            "loss nan acc 0.09375:  36%|███▌      | 21/58 [00:05<00:07,  4.71it/s]\u001b[A\n",
            "loss nan acc 0.09375:  38%|███▊      | 22/58 [00:05<00:07,  4.95it/s]\u001b[A\n",
            "loss nan acc 0.09443:  38%|███▊      | 22/58 [00:05<00:07,  4.95it/s]\u001b[A\n",
            "loss nan acc 0.09443:  40%|███▉      | 23/58 [00:05<00:06,  5.02it/s]\u001b[A\n",
            "loss nan acc 0.09701:  40%|███▉      | 23/58 [00:05<00:06,  5.02it/s]\u001b[A\n",
            "loss nan acc 0.09701:  41%|████▏     | 24/58 [00:05<00:06,  5.13it/s]\u001b[A\n",
            "loss nan acc 0.09750:  41%|████▏     | 24/58 [00:05<00:06,  5.13it/s]\u001b[A\n",
            "loss nan acc 0.09750:  43%|████▎     | 25/58 [00:05<00:06,  5.20it/s]\u001b[A\n",
            "loss nan acc 0.09916:  43%|████▎     | 25/58 [00:06<00:06,  5.20it/s]\u001b[A\n",
            "loss nan acc 0.09916:  45%|████▍     | 26/58 [00:06<00:06,  5.29it/s]\u001b[A\n",
            "loss nan acc 0.09954:  45%|████▍     | 26/58 [00:06<00:06,  5.29it/s]\u001b[A\n",
            "loss nan acc 0.09954:  47%|████▋     | 27/58 [00:06<00:05,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10156:  47%|████▋     | 27/58 [00:06<00:05,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10156:  48%|████▊     | 28/58 [00:06<00:05,  5.32it/s]\u001b[A\n",
            "loss nan acc 0.09968:  48%|████▊     | 28/58 [00:06<00:05,  5.32it/s]\u001b[A\n",
            "loss nan acc 0.09968:  50%|█████     | 29/58 [00:06<00:05,  5.23it/s]\u001b[A\n",
            "loss nan acc 0.10052:  50%|█████     | 29/58 [00:06<00:05,  5.23it/s]\u001b[A\n",
            "loss nan acc 0.10052:  52%|█████▏    | 30/58 [00:06<00:05,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10282:  52%|█████▏    | 30/58 [00:06<00:05,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10282:  53%|█████▎    | 31/58 [00:06<00:04,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10352:  53%|█████▎    | 31/58 [00:07<00:04,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10352:  55%|█████▌    | 32/58 [00:07<00:04,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10227:  55%|█████▌    | 32/58 [00:07<00:04,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10227:  57%|█████▋    | 33/58 [00:07<00:04,  5.40it/s]\u001b[A\n",
            "loss nan acc 0.10202:  57%|█████▋    | 33/58 [00:07<00:04,  5.40it/s]\u001b[A\n",
            "loss nan acc 0.10202:  59%|█████▊    | 34/58 [00:07<00:04,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10402:  59%|█████▊    | 34/58 [00:07<00:04,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10402:  60%|██████    | 35/58 [00:07<00:04,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10286:  60%|██████    | 35/58 [00:07<00:04,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10286:  62%|██████▏   | 36/58 [00:07<00:03,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10431:  62%|██████▏   | 36/58 [00:08<00:03,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10431:  64%|██████▍   | 37/58 [00:08<00:03,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10403:  64%|██████▍   | 37/58 [00:08<00:03,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10403:  66%|██████▌   | 38/58 [00:08<00:03,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.10337:  66%|██████▌   | 38/58 [00:08<00:03,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.10337:  67%|██████▋   | 39/58 [00:08<00:03,  5.46it/s]\u001b[A\n",
            "loss nan acc 0.10273:  67%|██████▋   | 39/58 [00:08<00:03,  5.46it/s]\u001b[A\n",
            "loss nan acc 0.10273:  69%|██████▉   | 40/58 [00:08<00:03,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10290:  69%|██████▉   | 40/58 [00:08<00:03,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10290:  71%|███████   | 41/58 [00:08<00:03,  5.46it/s]\u001b[A\n",
            "loss nan acc 0.10379:  71%|███████   | 41/58 [00:08<00:03,  5.46it/s]\u001b[A\n",
            "loss nan acc 0.10379:  72%|███████▏  | 42/58 [00:09<00:02,  5.36it/s]\u001b[A\n",
            "loss nan acc 0.10392:  72%|███████▏  | 42/58 [00:09<00:02,  5.36it/s]\u001b[A\n",
            "loss nan acc 0.10392:  74%|███████▍  | 43/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10334:  74%|███████▍  | 43/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10334:  76%|███████▌  | 44/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10417:  76%|███████▌  | 44/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10417:  78%|███████▊  | 45/58 [00:09<00:02,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10462:  78%|███████▊  | 45/58 [00:09<00:02,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10462:  79%|███████▉  | 46/58 [00:09<00:02,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10372:  79%|███████▉  | 46/58 [00:09<00:02,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10372:  81%|████████  | 47/58 [00:09<00:01,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10384:  81%|████████  | 47/58 [00:10<00:01,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10384:  83%|████████▎ | 48/58 [00:10<00:01,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10332:  83%|████████▎ | 48/58 [00:10<00:01,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10332:  84%|████████▍ | 49/58 [00:10<00:01,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10250:  84%|████████▍ | 49/58 [00:10<00:01,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10250:  86%|████████▌ | 50/58 [00:10<00:01,  5.59it/s]\u001b[A\n",
            "loss nan acc 0.10141:  86%|████████▌ | 50/58 [00:10<00:01,  5.59it/s]\u001b[A\n",
            "loss nan acc 0.10141:  88%|████████▊ | 51/58 [00:10<00:01,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10096:  88%|████████▊ | 51/58 [00:10<00:01,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10096:  90%|████████▉ | 52/58 [00:10<00:01,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10142:  90%|████████▉ | 52/58 [00:10<00:01,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10142:  91%|█████████▏| 53/58 [00:10<00:00,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10156:  91%|█████████▏| 53/58 [00:11<00:00,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10156:  93%|█████████▎| 54/58 [00:11<00:00,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10085:  93%|█████████▎| 54/58 [00:11<00:00,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10085:  95%|█████████▍| 55/58 [00:11<00:00,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10240:  95%|█████████▍| 55/58 [00:11<00:00,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10240:  97%|█████████▋| 56/58 [00:11<00:00,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10197:  97%|█████████▋| 56/58 [00:11<00:00,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10197:  98%|█████████▊| 57/58 [00:11<00:00,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.10022: 100%|██████████| 58/58 [00:11<00:00,  4.92it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 loss nan acc 0.10022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\n",
            "\n",
            "loss nan acc 0.14062:   0%|          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "loss nan acc 0.14062:   2%|▏         | 1/58 [00:00<00:22,  2.56it/s]\u001b[A\n",
            "loss nan acc 0.16406:   2%|▏         | 1/58 [00:00<00:22,  2.56it/s]\u001b[A\n",
            "loss nan acc 0.16406:   3%|▎         | 2/58 [00:00<00:14,  3.79it/s]\u001b[A\n",
            "loss nan acc 0.13021:   3%|▎         | 2/58 [00:00<00:14,  3.79it/s]\u001b[A\n",
            "loss nan acc 0.13021:   5%|▌         | 3/58 [00:00<00:12,  4.36it/s]\u001b[A\n",
            "loss nan acc 0.12891:   5%|▌         | 3/58 [00:00<00:12,  4.36it/s]\u001b[A\n",
            "loss nan acc 0.12891:   7%|▋         | 4/58 [00:00<00:11,  4.79it/s]\u001b[A\n",
            "loss nan acc 0.13125:   7%|▋         | 4/58 [00:01<00:11,  4.79it/s]\u001b[A\n",
            "loss nan acc 0.13125:   9%|▊         | 5/58 [00:01<00:10,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.12500:   9%|▊         | 5/58 [00:01<00:10,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.12500:  10%|█         | 6/58 [00:01<00:09,  5.25it/s]\u001b[A\n",
            "loss nan acc 0.12500:  10%|█         | 6/58 [00:01<00:09,  5.25it/s]\u001b[A\n",
            "loss nan acc 0.12500:  12%|█▏        | 7/58 [00:01<00:09,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.11719:  12%|█▏        | 7/58 [00:01<00:09,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.11719:  14%|█▍        | 8/58 [00:01<00:09,  5.32it/s]\u001b[A\n",
            "loss nan acc 0.11111:  14%|█▍        | 8/58 [00:01<00:09,  5.32it/s]\u001b[A\n",
            "loss nan acc 0.11111:  16%|█▌        | 9/58 [00:01<00:09,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.10938:  16%|█▌        | 9/58 [00:02<00:09,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.10938:  17%|█▋        | 10/58 [00:02<00:08,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10795:  17%|█▋        | 10/58 [00:02<00:08,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10795:  19%|█▉        | 11/58 [00:02<00:08,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.10286:  19%|█▉        | 11/58 [00:02<00:08,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.10286:  21%|██        | 12/58 [00:02<00:08,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.10337:  21%|██        | 12/58 [00:02<00:08,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.10337:  22%|██▏       | 13/58 [00:02<00:08,  5.16it/s]\u001b[A\n",
            "loss nan acc 0.09821:  22%|██▏       | 13/58 [00:02<00:08,  5.16it/s]\u001b[A\n",
            "loss nan acc 0.09821:  24%|██▍       | 14/58 [00:02<00:09,  4.52it/s]\u001b[A\n",
            "loss nan acc 0.09792:  24%|██▍       | 14/58 [00:03<00:09,  4.52it/s]\u001b[A\n",
            "loss nan acc 0.09792:  26%|██▌       | 15/58 [00:03<00:10,  4.13it/s]\u001b[A\n",
            "loss nan acc 0.09570:  26%|██▌       | 15/58 [00:03<00:10,  4.13it/s]\u001b[A\n",
            "loss nan acc 0.09570:  28%|██▊       | 16/58 [00:03<00:11,  3.82it/s]\u001b[A\n",
            "loss nan acc 0.09651:  28%|██▊       | 16/58 [00:03<00:11,  3.82it/s]\u001b[A\n",
            "loss nan acc 0.09651:  29%|██▉       | 17/58 [00:03<00:11,  3.67it/s]\u001b[A\n",
            "loss nan acc 0.09722:  29%|██▉       | 17/58 [00:04<00:11,  3.67it/s]\u001b[A\n",
            "loss nan acc 0.09722:  31%|███       | 18/58 [00:04<00:11,  3.58it/s]\u001b[A\n",
            "loss nan acc 0.09539:  31%|███       | 18/58 [00:04<00:11,  3.58it/s]\u001b[A\n",
            "loss nan acc 0.09539:  33%|███▎      | 19/58 [00:04<00:10,  3.55it/s]\u001b[A\n",
            "loss nan acc 0.09531:  33%|███▎      | 19/58 [00:04<00:10,  3.55it/s]\u001b[A\n",
            "loss nan acc 0.09531:  34%|███▍      | 20/58 [00:04<00:10,  3.53it/s]\u001b[A\n",
            "loss nan acc 0.09747:  34%|███▍      | 20/58 [00:04<00:10,  3.53it/s]\u001b[A\n",
            "loss nan acc 0.09747:  36%|███▌      | 21/58 [00:04<00:10,  3.49it/s]\u001b[A\n",
            "loss nan acc 0.09801:  36%|███▌      | 21/58 [00:05<00:10,  3.49it/s]\u001b[A\n",
            "loss nan acc 0.09801:  38%|███▊      | 22/58 [00:05<00:10,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.09783:  38%|███▊      | 22/58 [00:05<00:10,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.09783:  40%|███▉      | 23/58 [00:05<00:10,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.09570:  40%|███▉      | 23/58 [00:05<00:10,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.09570:  41%|████▏     | 24/58 [00:05<00:10,  3.39it/s]\u001b[A\n",
            "loss nan acc 0.09688:  41%|████▏     | 24/58 [00:06<00:10,  3.39it/s]\u001b[A\n",
            "loss nan acc 0.09688:  43%|████▎     | 25/58 [00:06<00:08,  3.73it/s]\u001b[A\n",
            "loss nan acc 0.09916:  43%|████▎     | 25/58 [00:06<00:08,  3.73it/s]\u001b[A\n",
            "loss nan acc 0.09916:  45%|████▍     | 26/58 [00:06<00:07,  4.12it/s]\u001b[A\n",
            "loss nan acc 0.09896:  45%|████▍     | 26/58 [00:06<00:07,  4.12it/s]\u001b[A\n",
            "loss nan acc 0.09896:  47%|████▋     | 27/58 [00:06<00:06,  4.43it/s]\u001b[A\n",
            "loss nan acc 0.10100:  47%|████▋     | 27/58 [00:06<00:06,  4.43it/s]\u001b[A\n",
            "loss nan acc 0.10100:  48%|████▊     | 28/58 [00:06<00:06,  4.75it/s]\u001b[A\n",
            "loss nan acc 0.10291:  48%|████▊     | 28/58 [00:06<00:06,  4.75it/s]\u001b[A\n",
            "loss nan acc 0.10291:  50%|█████     | 29/58 [00:06<00:05,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.10208:  50%|█████     | 29/58 [00:06<00:05,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.10208:  52%|█████▏    | 30/58 [00:06<00:05,  5.12it/s]\u001b[A\n",
            "loss nan acc 0.10232:  52%|█████▏    | 30/58 [00:07<00:05,  5.12it/s]\u001b[A\n",
            "loss nan acc 0.10232:  53%|█████▎    | 31/58 [00:07<00:05,  5.22it/s]\u001b[A\n",
            "loss nan acc 0.10107:  53%|█████▎    | 31/58 [00:07<00:05,  5.22it/s]\u001b[A\n",
            "loss nan acc 0.10107:  55%|█████▌    | 32/58 [00:07<00:04,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10180:  55%|█████▌    | 32/58 [00:07<00:04,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10180:  57%|█████▋    | 33/58 [00:07<00:04,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10156:  57%|█████▋    | 33/58 [00:07<00:04,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10156:  59%|█████▊    | 34/58 [00:07<00:04,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10134:  59%|█████▊    | 34/58 [00:07<00:04,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10134:  60%|██████    | 35/58 [00:07<00:04,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.10069:  60%|██████    | 35/58 [00:08<00:04,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.10069:  62%|██████▏   | 36/58 [00:08<00:04,  5.48it/s]\u001b[A\n",
            "loss nan acc 0.10008:  62%|██████▏   | 36/58 [00:08<00:04,  5.48it/s]\u001b[A\n",
            "loss nan acc 0.10008:  64%|██████▍   | 37/58 [00:08<00:03,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.09992:  64%|██████▍   | 37/58 [00:08<00:03,  5.47it/s]\u001b[A\n",
            "loss nan acc 0.09992:  66%|██████▌   | 38/58 [00:08<00:03,  5.58it/s]\u001b[A\n",
            "loss nan acc 0.10096:  66%|██████▌   | 38/58 [00:08<00:03,  5.58it/s]\u001b[A\n",
            "loss nan acc 0.10096:  67%|██████▋   | 39/58 [00:08<00:03,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10234:  67%|██████▋   | 39/58 [00:08<00:03,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10234:  69%|██████▉   | 40/58 [00:08<00:03,  5.58it/s]\u001b[A\n",
            "loss nan acc 0.10290:  69%|██████▉   | 40/58 [00:08<00:03,  5.58it/s]\u001b[A\n",
            "loss nan acc 0.10290:  71%|███████   | 41/58 [00:08<00:03,  5.58it/s]\u001b[A\n",
            "loss nan acc 0.10417:  71%|███████   | 41/58 [00:09<00:03,  5.58it/s]\u001b[A\n",
            "loss nan acc 0.10417:  72%|███████▏  | 42/58 [00:09<00:02,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.10356:  72%|███████▏  | 42/58 [00:09<00:02,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.10356:  74%|███████▍  | 43/58 [00:09<00:02,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10298:  74%|███████▍  | 43/58 [00:09<00:02,  5.55it/s]\u001b[A\n",
            "loss nan acc 0.10298:  76%|███████▌  | 44/58 [00:09<00:02,  5.54it/s]\u001b[A\n",
            "loss nan acc 0.10347:  76%|███████▌  | 44/58 [00:09<00:02,  5.54it/s]\u001b[A\n",
            "loss nan acc 0.10347:  78%|███████▊  | 45/58 [00:09<00:02,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.10224:  78%|███████▊  | 45/58 [00:09<00:02,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.10224:  79%|███████▉  | 46/58 [00:09<00:02,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.10106:  79%|███████▉  | 46/58 [00:10<00:02,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.10106:  81%|████████  | 47/58 [00:10<00:01,  5.57it/s]\u001b[A\n",
            "loss nan acc 0.10091:  81%|████████  | 47/58 [00:10<00:01,  5.57it/s]\u001b[A\n",
            "loss nan acc 0.10091:  83%|████████▎ | 48/58 [00:10<00:01,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10108:  83%|████████▎ | 48/58 [00:10<00:01,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.10108:  84%|████████▍ | 49/58 [00:10<00:01,  5.49it/s]\u001b[A\n",
            "loss nan acc 0.10156:  84%|████████▍ | 49/58 [00:10<00:01,  5.49it/s]\u001b[A\n",
            "loss nan acc 0.10156:  86%|████████▌ | 50/58 [00:10<00:01,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.10141:  86%|████████▌ | 50/58 [00:10<00:01,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.10141:  88%|████████▊ | 51/58 [00:10<00:01,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10126:  88%|████████▊ | 51/58 [00:10<00:01,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.10126:  90%|████████▉ | 52/58 [00:10<00:01,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.10053:  90%|████████▉ | 52/58 [00:11<00:01,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.10053:  91%|█████████▏| 53/58 [00:11<00:00,  5.46it/s]\u001b[A\n",
            "loss nan acc 0.10098:  91%|█████████▏| 53/58 [00:11<00:00,  5.46it/s]\u001b[A\n",
            "loss nan acc 0.10098:  93%|█████████▎| 54/58 [00:11<00:00,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10114:  93%|█████████▎| 54/58 [00:11<00:00,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10114:  95%|█████████▍| 55/58 [00:11<00:00,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.10184:  95%|█████████▍| 55/58 [00:11<00:00,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.10184:  97%|█████████▋| 56/58 [00:11<00:00,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10143:  97%|█████████▋| 56/58 [00:11<00:00,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10143:  98%|█████████▊| 57/58 [00:11<00:00,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10149: 100%|██████████| 58/58 [00:11<00:00,  4.86it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 loss nan acc 0.10149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\n",
            "\n",
            "loss nan acc 0.09375:   0%|          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "loss nan acc 0.09375:   2%|▏         | 1/58 [00:00<00:11,  4.91it/s]\u001b[A\n",
            "loss nan acc 0.08594:   2%|▏         | 1/58 [00:00<00:11,  4.91it/s]\u001b[A\n",
            "loss nan acc 0.08594:   3%|▎         | 2/58 [00:00<00:10,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.10938:   3%|▎         | 2/58 [00:00<00:10,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.10938:   5%|▌         | 3/58 [00:00<00:10,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.10938:   5%|▌         | 3/58 [00:00<00:10,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.10938:   7%|▋         | 4/58 [00:00<00:10,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.11563:   7%|▋         | 4/58 [00:00<00:10,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.11563:   9%|▊         | 5/58 [00:00<00:10,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.11458:   9%|▊         | 5/58 [00:01<00:10,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.11458:  10%|█         | 6/58 [00:01<00:09,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.11830:  10%|█         | 6/58 [00:01<00:09,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.11830:  12%|█▏        | 7/58 [00:01<00:10,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.11328:  12%|█▏        | 7/58 [00:01<00:10,  5.05it/s]\u001b[A\n",
            "loss nan acc 0.11328:  14%|█▍        | 8/58 [00:01<00:09,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10417:  14%|█▍        | 8/58 [00:01<00:09,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10417:  16%|█▌        | 9/58 [00:01<00:09,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10156:  16%|█▌        | 9/58 [00:01<00:09,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10156:  17%|█▋        | 10/58 [00:01<00:09,  5.27it/s]\u001b[A\n",
            "loss nan acc 0.10227:  17%|█▋        | 10/58 [00:02<00:09,  5.27it/s]\u001b[A\n",
            "loss nan acc 0.10227:  19%|█▉        | 11/58 [00:02<00:08,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.09896:  19%|█▉        | 11/58 [00:02<00:08,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.09896:  21%|██        | 12/58 [00:02<00:08,  5.21it/s]\u001b[A\n",
            "loss nan acc 0.10216:  21%|██        | 12/58 [00:02<00:08,  5.21it/s]\u001b[A\n",
            "loss nan acc 0.10216:  22%|██▏       | 13/58 [00:02<00:08,  5.04it/s]\u001b[A\n",
            "loss nan acc 0.10603:  22%|██▏       | 13/58 [00:02<00:08,  5.04it/s]\u001b[A\n",
            "loss nan acc 0.10603:  24%|██▍       | 14/58 [00:02<00:08,  5.14it/s]\u001b[A\n",
            "loss nan acc 0.10417:  24%|██▍       | 14/58 [00:02<00:08,  5.14it/s]\u001b[A\n",
            "loss nan acc 0.10417:  26%|██▌       | 15/58 [00:02<00:08,  5.23it/s]\u001b[A\n",
            "loss nan acc 0.10352:  26%|██▌       | 15/58 [00:03<00:08,  5.23it/s]\u001b[A\n",
            "loss nan acc 0.10352:  28%|██▊       | 16/58 [00:03<00:07,  5.29it/s]\u001b[A\n",
            "loss nan acc 0.10018:  28%|██▊       | 16/58 [00:03<00:07,  5.29it/s]\u001b[A\n",
            "loss nan acc 0.10018:  29%|██▉       | 17/58 [00:03<00:07,  5.25it/s]\u001b[A\n",
            "loss nan acc 0.09983:  29%|██▉       | 17/58 [00:03<00:07,  5.25it/s]\u001b[A\n",
            "loss nan acc 0.09983:  31%|███       | 18/58 [00:03<00:07,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.10033:  31%|███       | 18/58 [00:03<00:07,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.10033:  33%|███▎      | 19/58 [00:03<00:07,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.10078:  33%|███▎      | 19/58 [00:03<00:07,  5.31it/s]\u001b[A\n",
            "loss nan acc 0.10078:  34%|███▍      | 20/58 [00:03<00:06,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10417:  34%|███▍      | 20/58 [00:03<00:06,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10417:  36%|███▌      | 21/58 [00:03<00:06,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.09943:  36%|███▌      | 21/58 [00:04<00:06,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.09943:  38%|███▊      | 22/58 [00:04<00:07,  4.81it/s]\u001b[A\n",
            "loss nan acc 0.10326:  38%|███▊      | 22/58 [00:04<00:07,  4.81it/s]\u001b[A\n",
            "loss nan acc 0.10326:  40%|███▉      | 23/58 [00:04<00:08,  4.26it/s]\u001b[A\n",
            "loss nan acc 0.10547:  40%|███▉      | 23/58 [00:04<00:08,  4.26it/s]\u001b[A\n",
            "loss nan acc 0.10547:  41%|████▏     | 24/58 [00:04<00:08,  3.92it/s]\u001b[A\n",
            "loss nan acc 0.10437:  41%|████▏     | 24/58 [00:05<00:08,  3.92it/s]\u001b[A\n",
            "loss nan acc 0.10437:  43%|████▎     | 25/58 [00:05<00:08,  3.77it/s]\u001b[A\n",
            "loss nan acc 0.10337:  43%|████▎     | 25/58 [00:05<00:08,  3.77it/s]\u001b[A\n",
            "loss nan acc 0.10337:  45%|████▍     | 26/58 [00:05<00:09,  3.55it/s]\u001b[A\n",
            "loss nan acc 0.10301:  45%|████▍     | 26/58 [00:05<00:09,  3.55it/s]\u001b[A\n",
            "loss nan acc 0.10301:  47%|████▋     | 27/58 [00:05<00:08,  3.55it/s]\u001b[A\n",
            "loss nan acc 0.10714:  47%|████▋     | 27/58 [00:06<00:08,  3.55it/s]\u001b[A\n",
            "loss nan acc 0.10714:  48%|████▊     | 28/58 [00:06<00:08,  3.54it/s]\u001b[A\n",
            "loss nan acc 0.10668:  48%|████▊     | 28/58 [00:06<00:08,  3.54it/s]\u001b[A\n",
            "loss nan acc 0.10668:  50%|█████     | 29/58 [00:06<00:08,  3.52it/s]\u001b[A\n",
            "loss nan acc 0.10677:  50%|█████     | 29/58 [00:06<00:08,  3.52it/s]\u001b[A\n",
            "loss nan acc 0.10677:  52%|█████▏    | 30/58 [00:06<00:08,  3.41it/s]\u001b[A\n",
            "loss nan acc 0.10585:  52%|█████▏    | 30/58 [00:06<00:08,  3.41it/s]\u001b[A\n",
            "loss nan acc 0.10585:  53%|█████▎    | 31/58 [00:06<00:07,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.10645:  53%|█████▎    | 31/58 [00:07<00:07,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.10645:  55%|█████▌    | 32/58 [00:07<00:07,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.10559:  55%|█████▌    | 32/58 [00:07<00:07,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.10559:  57%|█████▋    | 33/58 [00:07<00:06,  3.74it/s]\u001b[A\n",
            "loss nan acc 0.10708:  57%|█████▋    | 33/58 [00:07<00:06,  3.74it/s]\u001b[A\n",
            "loss nan acc 0.10708:  59%|█████▊    | 34/58 [00:07<00:05,  4.11it/s]\u001b[A\n",
            "loss nan acc 0.10759:  59%|█████▊    | 34/58 [00:07<00:05,  4.11it/s]\u001b[A\n",
            "loss nan acc 0.10759:  60%|██████    | 35/58 [00:07<00:05,  4.46it/s]\u001b[A\n",
            "loss nan acc 0.10634:  60%|██████    | 35/58 [00:07<00:05,  4.46it/s]\u001b[A\n",
            "loss nan acc 0.10634:  62%|██████▏   | 36/58 [00:07<00:04,  4.73it/s]\u001b[A\n",
            "loss nan acc 0.10431:  62%|██████▏   | 36/58 [00:08<00:04,  4.73it/s]\u001b[A\n",
            "loss nan acc 0.10431:  64%|██████▍   | 37/58 [00:08<00:04,  5.01it/s]\u001b[A\n",
            "loss nan acc 0.10403:  64%|██████▍   | 37/58 [00:08<00:04,  5.01it/s]\u001b[A\n",
            "loss nan acc 0.10403:  66%|██████▌   | 38/58 [00:08<00:03,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10377:  66%|██████▌   | 38/58 [00:08<00:03,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10377:  67%|██████▋   | 39/58 [00:08<00:03,  5.27it/s]\u001b[A\n",
            "loss nan acc 0.10273:  67%|██████▋   | 39/58 [00:08<00:03,  5.27it/s]\u001b[A\n",
            "loss nan acc 0.10273:  69%|██████▉   | 40/58 [00:08<00:03,  5.36it/s]\u001b[A\n",
            "loss nan acc 0.10404:  69%|██████▉   | 40/58 [00:08<00:03,  5.36it/s]\u001b[A\n",
            "loss nan acc 0.10404:  71%|███████   | 41/58 [00:08<00:03,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10379:  71%|███████   | 41/58 [00:09<00:03,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10379:  72%|███████▏  | 42/58 [00:09<00:02,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10392:  72%|███████▏  | 42/58 [00:09<00:02,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.10392:  74%|███████▍  | 43/58 [00:09<00:02,  5.49it/s]\u001b[A\n",
            "loss nan acc 0.10369:  74%|███████▍  | 43/58 [00:09<00:02,  5.49it/s]\u001b[A\n",
            "loss nan acc 0.10369:  76%|███████▌  | 44/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10312:  76%|███████▌  | 44/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10312:  78%|███████▊  | 45/58 [00:09<00:02,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10258:  78%|███████▊  | 45/58 [00:09<00:02,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10258:  79%|███████▉  | 46/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10273:  79%|███████▉  | 46/58 [00:09<00:02,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10273:  81%|████████  | 47/58 [00:09<00:02,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10254:  81%|████████  | 47/58 [00:10<00:02,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10254:  83%|████████▎ | 48/58 [00:10<00:01,  5.54it/s]\u001b[A\n",
            "loss nan acc 0.10300:  83%|████████▎ | 48/58 [00:10<00:01,  5.54it/s]\u001b[A\n",
            "loss nan acc 0.10300:  84%|████████▍ | 49/58 [00:10<00:01,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10312:  84%|████████▍ | 49/58 [00:10<00:01,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10312:  86%|████████▌ | 50/58 [00:10<00:01,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10294:  86%|████████▌ | 50/58 [00:10<00:01,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10294:  88%|████████▊ | 51/58 [00:10<00:01,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.10367:  88%|████████▊ | 51/58 [00:10<00:01,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.10367:  90%|████████▉ | 52/58 [00:10<00:01,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10259:  90%|████████▉ | 52/58 [00:11<00:01,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10259:  91%|█████████▏| 53/58 [00:11<00:00,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10214:  91%|█████████▏| 53/58 [00:11<00:00,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.10214:  93%|█████████▎| 54/58 [00:11<00:00,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10142:  93%|█████████▎| 54/58 [00:11<00:00,  5.41it/s]\u001b[A\n",
            "loss nan acc 0.10142:  95%|█████████▍| 55/58 [00:11<00:00,  5.22it/s]\u001b[A\n",
            "loss nan acc 0.10156:  95%|█████████▍| 55/58 [00:11<00:00,  5.22it/s]\u001b[A\n",
            "loss nan acc 0.10156:  97%|█████████▋| 56/58 [00:11<00:00,  5.20it/s]\u001b[A\n",
            "loss nan acc 0.10088:  97%|█████████▋| 56/58 [00:11<00:00,  5.20it/s]\u001b[A\n",
            "loss nan acc 0.10088:  98%|█████████▊| 57/58 [00:11<00:00,  5.26it/s]\u001b[A\n",
            "loss nan acc 0.10277: 100%|██████████| 58/58 [00:11<00:00,  4.87it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 loss nan acc 0.10277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\n",
            "\n",
            "loss nan acc 0.14062:   0%|          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "loss nan acc 0.14062:   2%|▏         | 1/58 [00:00<00:10,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.14062:   2%|▏         | 1/58 [00:00<00:10,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.14062:   3%|▎         | 2/58 [00:00<00:10,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.11458:   3%|▎         | 2/58 [00:00<00:10,  5.45it/s]\u001b[A\n",
            "loss nan acc 0.11458:   5%|▌         | 3/58 [00:00<00:09,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.09375:   5%|▌         | 3/58 [00:00<00:09,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.09375:   7%|▋         | 4/58 [00:00<00:10,  5.30it/s]\u001b[A\n",
            "loss nan acc 0.10625:   7%|▋         | 4/58 [00:00<00:10,  5.30it/s]\u001b[A\n",
            "loss nan acc 0.10625:   9%|▊         | 5/58 [00:00<00:10,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10417:   9%|▊         | 5/58 [00:01<00:10,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10417:  10%|█         | 6/58 [00:01<00:09,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.11384:  10%|█         | 6/58 [00:01<00:09,  5.34it/s]\u001b[A\n",
            "loss nan acc 0.11384:  12%|█▏        | 7/58 [00:01<00:09,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.11328:  12%|█▏        | 7/58 [00:01<00:09,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.11328:  14%|█▍        | 8/58 [00:01<00:09,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.11285:  14%|█▍        | 8/58 [00:01<00:09,  5.51it/s]\u001b[A\n",
            "loss nan acc 0.11285:  16%|█▌        | 9/58 [00:01<00:08,  5.48it/s]\u001b[A\n",
            "loss nan acc 0.11406:  16%|█▌        | 9/58 [00:01<00:08,  5.48it/s]\u001b[A\n",
            "loss nan acc 0.11406:  17%|█▋        | 10/58 [00:01<00:08,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.11080:  17%|█▋        | 10/58 [00:02<00:08,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.11080:  19%|█▉        | 11/58 [00:02<00:08,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.11198:  19%|█▉        | 11/58 [00:02<00:08,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.11198:  21%|██        | 12/58 [00:02<00:08,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.11298:  21%|██        | 12/58 [00:02<00:08,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.11298:  22%|██▏       | 13/58 [00:02<00:08,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.11161:  22%|██▏       | 13/58 [00:02<00:08,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.11161:  24%|██▍       | 14/58 [00:02<00:08,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.11354:  24%|██▍       | 14/58 [00:02<00:08,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.11354:  26%|██▌       | 15/58 [00:02<00:08,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.11328:  26%|██▌       | 15/58 [00:02<00:08,  5.35it/s]\u001b[A\n",
            "loss nan acc 0.11328:  28%|██▊       | 16/58 [00:02<00:07,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.11305:  28%|██▊       | 16/58 [00:03<00:07,  5.38it/s]\u001b[A\n",
            "loss nan acc 0.11305:  29%|██▉       | 17/58 [00:03<00:07,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.11372:  29%|██▉       | 17/58 [00:03<00:07,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.11372:  31%|███       | 18/58 [00:03<00:07,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.11184:  31%|███       | 18/58 [00:03<00:07,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.11184:  33%|███▎      | 19/58 [00:03<00:07,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.11016:  33%|███▎      | 19/58 [00:03<00:07,  5.53it/s]\u001b[A\n",
            "loss nan acc 0.11016:  34%|███▍      | 20/58 [00:03<00:06,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.11161:  34%|███▍      | 20/58 [00:03<00:06,  5.52it/s]\u001b[A\n",
            "loss nan acc 0.11161:  36%|███▌      | 21/58 [00:03<00:06,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.11222:  36%|███▌      | 21/58 [00:04<00:06,  5.43it/s]\u001b[A\n",
            "loss nan acc 0.11222:  38%|███▊      | 22/58 [00:04<00:06,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.11005:  38%|███▊      | 22/58 [00:04<00:06,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.11005:  40%|███▉      | 23/58 [00:04<00:06,  5.57it/s]\u001b[A\n",
            "loss nan acc 0.11068:  40%|███▉      | 23/58 [00:04<00:06,  5.57it/s]\u001b[A\n",
            "loss nan acc 0.11068:  41%|████▏     | 24/58 [00:04<00:06,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.11000:  41%|████▏     | 24/58 [00:04<00:06,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.11000:  43%|████▎     | 25/58 [00:04<00:05,  5.57it/s]\u001b[A\n",
            "loss nan acc 0.10998:  43%|████▎     | 25/58 [00:04<00:05,  5.57it/s]\u001b[A\n",
            "loss nan acc 0.10998:  45%|████▍     | 26/58 [00:04<00:05,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.10880:  45%|████▍     | 26/58 [00:04<00:05,  5.56it/s]\u001b[A\n",
            "loss nan acc 0.10880:  47%|████▋     | 27/58 [00:04<00:05,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10714:  47%|████▋     | 27/58 [00:05<00:05,  5.44it/s]\u001b[A\n",
            "loss nan acc 0.10714:  48%|████▊     | 28/58 [00:05<00:05,  5.49it/s]\u001b[A\n",
            "loss nan acc 0.10668:  48%|████▊     | 28/58 [00:05<00:05,  5.49it/s]\u001b[A\n",
            "loss nan acc 0.10668:  50%|█████     | 29/58 [00:05<00:05,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.10573:  50%|█████     | 29/58 [00:05<00:05,  5.50it/s]\u001b[A\n",
            "loss nan acc 0.10573:  52%|█████▏    | 30/58 [00:05<00:05,  4.97it/s]\u001b[A\n",
            "loss nan acc 0.10484:  52%|█████▏    | 30/58 [00:05<00:05,  4.97it/s]\u001b[A\n",
            "loss nan acc 0.10484:  53%|█████▎    | 31/58 [00:05<00:06,  4.49it/s]\u001b[A\n",
            "loss nan acc 0.10449:  53%|█████▎    | 31/58 [00:06<00:06,  4.49it/s]\u001b[A\n",
            "loss nan acc 0.10449:  55%|█████▌    | 32/58 [00:06<00:06,  4.11it/s]\u001b[A\n",
            "loss nan acc 0.10417:  55%|█████▌    | 32/58 [00:06<00:06,  4.11it/s]\u001b[A\n",
            "loss nan acc 0.10417:  57%|█████▋    | 33/58 [00:06<00:06,  3.86it/s]\u001b[A\n",
            "loss nan acc 0.10524:  57%|█████▋    | 33/58 [00:06<00:06,  3.86it/s]\u001b[A\n",
            "loss nan acc 0.10524:  59%|█████▊    | 34/58 [00:06<00:06,  3.73it/s]\u001b[A\n",
            "loss nan acc 0.10625:  59%|█████▊    | 34/58 [00:07<00:06,  3.73it/s]\u001b[A\n",
            "loss nan acc 0.10625:  60%|██████    | 35/58 [00:07<00:06,  3.62it/s]\u001b[A\n",
            "loss nan acc 0.10590:  60%|██████    | 35/58 [00:07<00:06,  3.62it/s]\u001b[A\n",
            "loss nan acc 0.10590:  62%|██████▏   | 36/58 [00:07<00:06,  3.59it/s]\u001b[A\n",
            "loss nan acc 0.10557:  62%|██████▏   | 36/58 [00:07<00:06,  3.59it/s]\u001b[A\n",
            "loss nan acc 0.10557:  64%|██████▍   | 37/58 [00:07<00:05,  3.58it/s]\u001b[A\n",
            "loss nan acc 0.10567:  64%|██████▍   | 37/58 [00:07<00:05,  3.58it/s]\u001b[A\n",
            "loss nan acc 0.10567:  66%|██████▌   | 38/58 [00:07<00:05,  3.54it/s]\u001b[A\n",
            "loss nan acc 0.10617:  66%|██████▌   | 38/58 [00:08<00:05,  3.54it/s]\u001b[A\n",
            "loss nan acc 0.10617:  67%|██████▋   | 39/58 [00:08<00:05,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.10664:  67%|██████▋   | 39/58 [00:08<00:05,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.10664:  69%|██████▉   | 40/58 [00:08<00:05,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.10747:  69%|██████▉   | 40/58 [00:08<00:05,  3.44it/s]\u001b[A\n",
            "loss nan acc 0.10747:  71%|███████   | 41/58 [00:08<00:04,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.10751:  71%|███████   | 41/58 [00:08<00:04,  3.47it/s]\u001b[A\n",
            "loss nan acc 0.10751:  72%|███████▏  | 42/58 [00:08<00:04,  3.74it/s]\u001b[A\n",
            "loss nan acc 0.10647:  72%|███████▏  | 42/58 [00:09<00:04,  3.74it/s]\u001b[A\n",
            "loss nan acc 0.10647:  74%|███████▍  | 43/58 [00:09<00:03,  4.15it/s]\u001b[A\n",
            "loss nan acc 0.10440:  74%|███████▍  | 43/58 [00:09<00:03,  4.15it/s]\u001b[A\n",
            "loss nan acc 0.10440:  76%|███████▌  | 44/58 [00:09<00:03,  4.52it/s]\u001b[A\n",
            "loss nan acc 0.10382:  76%|███████▌  | 44/58 [00:09<00:03,  4.52it/s]\u001b[A\n",
            "loss nan acc 0.10382:  78%|███████▊  | 45/58 [00:09<00:02,  4.74it/s]\u001b[A\n",
            "loss nan acc 0.10326:  78%|███████▊  | 45/58 [00:09<00:02,  4.74it/s]\u001b[A\n",
            "loss nan acc 0.10326:  79%|███████▉  | 46/58 [00:09<00:02,  4.91it/s]\u001b[A\n",
            "loss nan acc 0.10140:  79%|███████▉  | 46/58 [00:09<00:02,  4.91it/s]\u001b[A\n",
            "loss nan acc 0.10140:  81%|████████  | 47/58 [00:09<00:02,  4.98it/s]\u001b[A\n",
            "loss nan acc 0.10189:  81%|████████  | 47/58 [00:10<00:02,  4.98it/s]\u001b[A\n",
            "loss nan acc 0.10189:  83%|████████▎ | 48/58 [00:10<00:01,  5.04it/s]\u001b[A\n",
            "loss nan acc 0.10268:  83%|████████▎ | 48/58 [00:10<00:01,  5.04it/s]\u001b[A\n",
            "loss nan acc 0.10268:  84%|████████▍ | 49/58 [00:10<00:01,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10219:  84%|████████▍ | 49/58 [00:10<00:01,  5.17it/s]\u001b[A\n",
            "loss nan acc 0.10219:  86%|████████▌ | 50/58 [00:10<00:01,  5.20it/s]\u001b[A\n",
            "loss nan acc 0.10233:  86%|████████▌ | 50/58 [00:10<00:01,  5.20it/s]\u001b[A\n",
            "loss nan acc 0.10233:  88%|████████▊ | 51/58 [00:10<00:01,  5.24it/s]\u001b[A\n",
            "loss nan acc 0.10216:  88%|████████▊ | 51/58 [00:10<00:01,  5.24it/s]\u001b[A\n",
            "loss nan acc 0.10216:  90%|████████▉ | 52/58 [00:10<00:01,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10112:  90%|████████▉ | 52/58 [00:10<00:01,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10112:  91%|█████████▏| 53/58 [00:11<00:00,  5.29it/s]\u001b[A\n",
            "loss nan acc 0.10012:  91%|█████████▏| 53/58 [00:11<00:00,  5.29it/s]\u001b[A\n",
            "loss nan acc 0.10012:  93%|█████████▎| 54/58 [00:11<00:00,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10028:  93%|█████████▎| 54/58 [00:11<00:00,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10028:  95%|█████████▍| 55/58 [00:11<00:00,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.09989:  95%|█████████▍| 55/58 [00:11<00:00,  5.42it/s]\u001b[A\n",
            "loss nan acc 0.09989:  97%|█████████▋| 56/58 [00:11<00:00,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10088:  97%|█████████▋| 56/58 [00:11<00:00,  5.37it/s]\u001b[A\n",
            "loss nan acc 0.10088:  98%|█████████▊| 57/58 [00:11<00:00,  5.39it/s]\u001b[A\n",
            "loss nan acc 0.10277: 100%|██████████| 58/58 [00:11<00:00,  4.91it/s]\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 loss nan acc 0.10277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(torch.randn(64, 1, 28, 28))\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJmTAdtbQjRj",
        "outputId": "e60a6bc1-f49e-4664-dc17-cdc30b838001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader['train']:\n",
        "  x = batch[0]\n",
        "  print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN_7BEUISgc1",
        "outputId": "b1c47ba5-94b4-404b-e9bd-65d217096874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([19, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gui1FkZ2SjOA",
        "outputId": "c7eed460-6dde-4d41-bdb2-63d92a55bfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f13c9fb6160>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}